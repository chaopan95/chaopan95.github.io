---
layout: page
title:  "树"
---
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


{:toc}

* 
{:toc}



<style>
table {
  border-collapse: collapse;
  border: 1px solid black;
  margin: 0 auto;
} 

th,td {
  border: 1px solid black;
  text-align: center;
  padding: 20px;
}

table.a {
  table-layout: auto;
  width: 180px;  
}

table.b {
  table-layout: fixed;
  width: 600px;  
}

table.c {
  table-layout: auto;
  width: 100%;  
}

table.d {
  table-layout: fixed;
  width: 100%;  
}
</style>


## 5. Tree
<p align="justify">
Tree is a special graph (V, E), number of nodes is |V|, number of edges is |E|. A tree is an undirected graph in which any two vertices are connected by exactly one path, or equivalently a connected acyclic undirected graph.<br><br>

If a tree has n nodes, it has n-1 egdes. For any node except root, it havs a unique path from root to itself. Thus, it has a unique path length (path length = number of edges along this path).<br><br>

Height of tree = max path length. Depth = Height + 1. If a tree has only one node, its height is 0. If a null tree, its height is -1.
</p>

### 5.1 Binary tree
<p align="justify">
If any node in tree has no more than 2 children, we define this tree as binary tree.<br><br>

In a tree, depth k level has 2^k nodes<br><br>

If a tree has n nodes and its height is h, h < n < 2^(h+1).<br><br>

Proper binary tree: a binary tree whose all node has a even out degree (0 or 2).<br>
Complete Binary Tree: Except last level, each level is complete, last level should be filled at left.<br>
Perfect Binary Tree: Each non-leaf node has two children, all leaf nodes are located in a same level.
</p>

### 5.2 Traverse
#### 5.2.1 PreOrder: V L R
<p align="justify">
Recursive
</p>
<p align="justify">
Interative
</p>
{% highlight C++ %}
template<class T>//Iterative pre order
void BST<T>::iterPreOrder(node<T>*curNode)
{
	stack<node<T>*> tree;
	tree.push(curNode);
	while (!tree.empty())
	{
		curNode = tree.top();
		tree.pop();
		BST<T>::visit(curNode);
		if (curNode->right != nullptr)
		{
			tree.push(curNode->right);
		}
		if (curNode->left != nullptr)
		{
			tree.push(curNode->left);
		}
	}
}
{% endhighlight %}

#### 5.2.2 InOrder: L V R
<p align="justify">
Recursive
</p>
<p align="justify">
Interative
</p>
{% highlight C++ %}
template<class T>//iterative in order
void BST<T>::iterInOrder(node<T> *curNode)
{
	stack<node<T>*> tree;
	while (curNode != nullptr)
	{
		while (curNode != nullptr)
		{
			if (curNode->right != nullptr)
			{
				tree.push(curNode->right);
			}
			tree.push(curNode);
			curNode = curNode->left;
		}
		curNode = tree.top();
		tree.pop();
		while (!tree.empty() && curNode->right == nullptr)
		{
			visit(curNode);
			curNode = tree.top();
			tree.pop();
		}
		visit(curNode);
		if (!tree.empty())
		{
			curNode = tree.top();
			tree.pop();
		}
		else
		{
			curNode = nullptr;
		}
	}
}
{% endhighlight %}

#### 5.2.3 PostOrder: L R V
<p align="justify">
Recursive
</p>
<p align="justify">
Interative
</p>
{% highlight C++ %}
template <class T>//iterative post order
void BST<T>::iterPostOrder(node<T>*curNode)
{
	stack<node<T>*> tree;
	node<T>*p, *q;
	p = q = curNode;
	while (p != nullptr)
	{
		for (; p->left != nullptr; p = p->left)
		{
			tree.push(p);
		}
		while (p->right == nullptr || p->right == q)
		{
			visit(p);
			q = p;
			if (tree.empty())
			{
				return;
			}
			p = tree.top();
			tree.pop();
		}
		tree.push(p);
		p = p->right;
	}
}
{% endhighlight %}

#### 5.2.4 LevelOrder
{% highlight C++ %}
template<class T>//level order
void BST<T>::levelOrder(node<T>*curNode)
{
	node<T> *last, *nextLast, *front;
	queue<node<T>*> queueTree;
	queueTree.push(curNode);
	last = nextLast = front = curNode;
	while (!queueTree.empty())
	{
		front = queueTree.front();
		queueTree.pop();
		BST<T>::visit(front);
		if (front->left != nullptr)
		{
			queueTree.push(front->left);
			nextLast = front->left;
		}
		if (front->right != nullptr)
		{
			queueTree.push(front->right);
			nextLast = front->right;
		}
		if (front == last)
		{
			cout << endl;
			last = nextLast;
		}
	}
}
{% endhighlight %}

### 5.3 Reconsturction of binary tree
<p align="justify">
PreOrder/PostOrder + InOrder -> binary tree
</p>


## 6. Binary seach tree
<p align="justify">
Any node is not less than its left child and not more than its right child. Obviously, BST' in-order is monotonously increasing.
</p>

### 6.1 How many possible BST with n nodes
<p align="justify">
If we have 4 nodes like <b>1, 2, 3, 4</b>, how many possible BST with them?<br>
Considerate n = 0 (Null tree), possible number of BST f(n) = 1<br>
n = 1, f(n) = 1<br>
n = 2, f(n) = 2<br>
n = 3, suppose k (k = 1, 2, 3) as root node, its left subtree has (k-1) nodes, its right subtree has (n-k) node. Total possible BST
$$f(n)=\sum_{k=1}^{n}f(k-1)f(n-k)=catalan(n)=\frac{(2n)!}{(n+1)!n!}$$
</p>

### 6.2 Self-balancing BST
<p align="justify">
In computer science, a self-balancing binary search tree is any node-based binary search tree that automatically keeps its height small in the face of arbitrary item insertions and deletions.<br><br>

For non self-balancing BST, we can rotate it to be self-balancing BST.<br>
Ideally balanced: h = log(n); Moderately balanced: h <= O(log(n))
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rotation_bst.png"/></center>
</p>

### 6.3 AVL
<p align="justify">
AVL: Adelson-Velsky & E. Landis<br>
They define an AVL tree by balance factor:<br>
bf(v) = height(v's left subtree) - height(v's right subtree)<br>
For any node, |bf(v)| = 0 or 1<br>
</p>

#### 6.3.1 AVL ~ BBST
<p align="justify">
An AVL tree with a height of h, has at least S(h) = fib(h+3)-1 nodes.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_example.png"/></center>
</p>
<p align="justify">
We can write a recursive equation for number of one AVL tree with a height of h. Like the example above, left tree is more high than right tree.
$$S(h)=1+S(h-1)+S(h-2)$$
$$S(h)+1=S(h-1)+1+S(h-2)+1$$

Make T(h) = S(h)+1
$$T(h)=T(h-1)+T(h-2)$$

This is a standard Fibonacci sequence (1, 1, 2, 3, 5,...). Now, T(h) corresponds to which term of Fibonacci sequence?<br>
If h = 0, AVL tree has only one node, T(0) = S(0)+1 = 2, which is 3rd term<br>
If h = 1, AVL tree has 2 or 3 node, T(1) = S(1)+1 = 3 or 4, which is 4th term. Here we take inferior border.<br>
So, we get a relation
$$T(h) = S(h)+1 >= Fib(h+3)=N$$

Fib(n) increases in an exponential way. So, the number of nodes has an inferior border.
$$N \sim \Omega(\Phi^{h})$$

Naturally, h has a superior border
$$h \sim O(log(n))$$

Thus, AVL satisfies the requirement of BBST(balanced BST): moderately balanced
</p>

#### 6.3.2 Unbalanced
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_unbalanced.png"/></center>
<p align="justify">
If we insert or remove one element in an AVL tree, it may be unbalanced. In details, insert an element, several subtress are unbalanced, for example, insert M, its ancestors K, N, R and G are unbalanced; while remove Y, only its parent R is unbalanced.
</p>

#### 6.3.3 Single rotation
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_signle_rotation_insert.png"/></center>
<p align="justify">
From the example, after inserting a node in the subtree of v, g becomes unbalanced, while v and p are not. Well, g is wanted for us, because it is the deepest node among all unbalanced nodes after inserting one node. We performe a signle rotation on g. A case of three generations g, p, v towards right is called zagzag, in contrast, zigzig. Attention, after this rotation, all ancestors of g return balanced if they were unbalanced before. Why?<br><br>

Before inserting one node, we have a base line (foot of T2 and T3), after inserting, our base line goes down 1 and this breaks balance rule. Besides, we notice a height for v, p, g increase by 1. After a single rotation, our base line comes back. We know, before inserting, our tree is balanced. Now our base line returns, ancestor of g is also balanced.<br><br>

A single rotation for inserting one node is in O(1).
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_single_rotation_remove.png"/></center>
</p>
<p align="justify">
As for removing one node, this is some different with inserting. From the example above, we remove one node of T3, this tree becomes unbalanced, we perform a zig on g. Finally, our tree return balanced. If T2 has a node, our base line comes back, but unlickily if T2 has no node, our base line goes up compared to that before removing, which potentially provoke an unbalanced of some ancestor of g.<br><br>

We have to check other some nodes if balanced or not. In the worst condition, we have to perform log(n) single rotations after removing one node.
</p>

#### 6.3.4 Double rotation
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_double_rotation_insert.png"/></center>
<p align="justify">
How to solve a case like the example above g's right child is p and p's left child is v (or symmetry case)? Answer is double rotation(zagzig or zigzag)
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/avl_double_rotation_remove.png"/></center>
</p>
<p align="justify">
As for removing one node in case of zagzig pr zigzag, our base line will goes up compared to that before removing, which means some ancestor will be unbalanced.
</p>

#### 6.3.5 3+4 reconstruction
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/34_reconstruct.png"/></center>
<p align="justify">
1) Suppose g is the deepest node among all unbalanced node, we care about three generations: g, p, v<br>
2) Rename them as a, b, c in the way of in-order<br>
3) For g, p, v, there is totally 4 subtrees (some subtree is possible null). Siminarly, we rename them as T0, T1, T2, T3 with method of in-order<br>
4) Because of monotonicity of in-order, we have a sequence like T0, a, T1, b, T2, c, T3<br>
5) Reconstruct a tree<br>
We can unify signle ration and double rotation with 3+4 reconstruction regardless of inserting or removing.
</p>

#### 6.3.6 Evaulation
<p align="justify">
pros:<br>
Insert, remove, search in o(log(n)). Stockage in o(n)<br>
cons:<br>
Rotation costs much for removing one node: o(log(n) in worst condition, 0.21 in average condition)
Topological space variation after single modification in Omega(log(n))
</p>


## 7. Advanced seach tree
<p align="justify">
AVL has a relatively rigorous reauirement even if it has been relaxed form ideal balance by balance factor. But AVL still need much cost to maintain its balance when we perform some insert or remove. So some advanced search trees play a necessary role.
</p>

### 7.1 Splay tree
#### 7.1.1 Locality and Self-adjusting
<p align="justify">
Locality: Some visited data just now is likely to be visited once more in a small time periode. Take BST as instance, it is likely to visit some data many times in a short time.<br><br>

Self-adjusting: consider a list, one element' visiting efficiency depends on its rank in the list, the smaller its rank is (or the nearer to head), the bigger vist efficiency is. If this list has a locality, we can do something on the list. For example, if one element in the list is visited, we put this element in the position of head. After a while, some frequently visited elements are aggregated in the front of list.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/splaytree_list_tree_1.png"/></center>
</p>

#### 7.1.2 Single splay
<p align="justify">
Naturally, we can generalize this concept to a tree or BST. Concretely, list's head corresponds to tree's top anf list's tail correspons to tree's bottom.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/splaytree_list_tree_2.png"/></center>
</p>

<p align="justify">
So, we have a strategy: once one element is visited, we move it to the root of the tree by zig or zag. Because one zig or zag can level up an element once. We repeat zig or zag until the element is moved to root node.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/splaytree_zigzag.png"/></center>
</p>

<p align="justify">
We talk about the worst condition: we have a tree like this. We hope to search each element in a cycle.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/splaytree_worst_condition_1.png"/></center>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/splaytree_worst_condition_2.png"/></center>
</p>
<p align="justify">
We can find out a whole cycle is in $\Omega(n^{2})$ and amortized complexity is in $\Omega(n)$. This is much bigger than log(n). So, we have to do some change.
</p>

#### 7.1.3 Double splay
<p align="justify">
Double splay: for three generations g = parent(p), p = parent(v), v, lift v two levels to be root with at most 2 rotations.<br>
For zigzag (or zagzig), double splay has no difference avec single AVL and single splay: we have to zig on p then zag on g to left v two levels.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/double_splay_zigzag.png"/></center>
</p>
<p align="justify">
But for zigzig (or zagzag), double splay is different: zig on g then zig on p to lift v two levels while single splay zig on p then zig on g. According to their final result, these two splay manage to lift v two levels, but they have a different effect on the sub tree.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/double_splay_zigzig.png"/></center>
</p>
<p align="justify">
To clarify the difference between single splay and double splay on zagzag (or zigzig). We try to visit the deepest node.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/double_splay_zagzag_example.png"/></center>
</p>
<p align="justify">
The power of double splay is to reduce subtree's height in an exponential way, while single splay does the same thing in an arithmetic progression. amortized complexity for double splay is $O(log(n)))$.<br><br>

Obviously, there is a special case: v has no grandparent. In this case, v's parent is root for the whole tree. Then, one zig or zag (it depends on concrete morphology) is enough.<br><br>

Evaluation:<br>
No need to record height of node and balance factor, it is easier to implement than AVL<br>
amortized complexity is $O(log(n))$ which is equal to AVL<br>
If some locality exists, more efficient to visit cache data. In other word, during an interval of time, we visit some data more frequently. If we have n data, k data is much frequently visited, m is visiting times, so k << n << m. Then searching m times is in $O(mlog(k)+nlog(n))$.<br>
But splay tree cannot guarantee advoiding the worst condition and splay tree is not suitable for some occasion which is sensible for efficiency.
</p>

### 7.2 B-tree
<p align="justify">
640 KB ought to be enough for anybody. -- B. Gates, 1981<br><br>

Two facts:<br>
1 s = 1 day: if we visit RAM with 1 s, we visit a disk with 1 day.<br>
1 B = 1 KB: time of visiting 1B is nearly equal to that of visiting 1KB.
</p>

#### 7.2.1 Definition
<p align="justify">
B-tree (R. Bayer & E. McCreight) is a mutil-way tree. All external nodes (children of leaf node but null) have a same depth. The height of B-tree is from root to external nodes instead of leaf node. Each node is called super node.<br>
Merge 2 generations as a super node: 3 key values and 4 branches<br>
Merge d generations as a super node: $2^{d}-1$ key values and $m=2^{d}$ branches<br>
If there are N internal keys values in this B-tree, there are N+1 external nodes (key value is null)<br><br>

In fact, B-tree is logically equal to BBST. But, compared to BBST, B-tree visit a batch of values at each super node in order to reduce I/O, because each level represents one I/O.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_merge.png"/></center>
</p>
<p align="justify">
How many internal nodes in a m-way B-tree?<br>
At most m-1 key values and m branches; at least $\left \lceil \frac{m}{2} \right \rceil$ branches except root node with 2. Besides, we can call some B-tree according to its superior limit and inferior limit, e.g. we call 4-way B-tree (2, 4) tree and 7-way B-tree (4, 7) tree.<br><br>
</p>

#### 7.2.2 Height
<p align="justify">
If we have a m-way B-tree with N key value, what is it's maximun height?<br>
At each level, internal node should be as less as possible. $n_{0}=1$, $n_{1}=2$, $n_{2}=2\times \left \lceil \frac{m}{2} \right \rceil$<br>
For $k^{th}$ level ($k\geq 1$)
$$n_{k}=2\times \left \lceil \frac{m}{2} \right \rceil^{k-1}$$

For last level in which all external node are. Because there are N internal key value, external key values are N+1.
$$N+1=n_{h}\geq 2\times \left \lceil \frac{m}{2} \right \rceil^{h-1}$$

$$h\leq 1+log_{\left \lceil \frac{m}{2} \right \rceil}\left \lfloor \frac{N+1}{2} \right \rfloor=O(log_{m}N)$$

Compared to BBST
$$\frac{log_{\left \lceil \frac{m}{2} \right \rceil}\frac{N}{2}}{log_{2}N}=\frac{1}{log_{2}m-1}$$

A 256-way B-tree has a $\frac{1}{7}$ of BBST's height (I/O times)<br><br>

How about its minimum height?<br>
Each internal node has as many key values as possible. So, $n_{0}=1$, $n_{1}=m$, $n_{2} = m^{2}$, ..., $n_{h-1}=m^{h-1}$, $n_{h}=m^{h}$.<br>
For the last level in which all external node are
$$N+1=n_{h}\leq m^{h}$$

$$h\geq log_{m}(N+1)=\Omega(log_{m}N)$$

Compared to BBST
$$\frac{log_{m}N-1}{log_{2}N}=log_{m}2-log_{N}2=\frac{1}{log_{2}m}$$

A 256-way B-tree has a $\frac{1}{8}$ of BBST's height. In fact, a m-way B-tree has a relatively fixed height.
</p>

#### 7.2.3 Insert
<p align="justify">
If we insert a new key value in a super node and an overflow happens, we have to split this node. In fact, this super node has already m key values such as $k_{0}, k_{1}, ..., k_{m-1}$. We take its median $s=\left \lfloor \frac{m}{2} \right \rfloor$ and split all key values with $k_{s}$
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_overflow_1.png"/></center>
</p>
<p align="justify">
Besides, we lift $k_{s}$ one level to join its parent and set the rest 2 parts as left children and right children of $k_{s}$. For example, after inserting 37, overflow happens, we put 37 into its parent and set 17, 20, 31 as its left children and 41, 56 as its right children.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_overflow_2.png"/></center>
</p>
<p align="justify">
Possibly, this kind of overflow will pass upward until root. We split this super node and establish a new root and take $k_{s}$ a key value in this new root. For example, an overflow in root node, we establish a new node with only one key value 37, and set 17, 20, 31 as its left children and 41, 56 as its right children. At this time, height adds 1 and number of branches for the new root is 2.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_overflow_3.png"/></center>
</p>
<p align="justify">
Insert is in $O(h)$<br><br>
</p>

#### 7.2.4 Remove
<p align="justify">
As for removing, if some key value to be removed is not a leaf, we find its most left children in its right subtree and exchange their position, then remove the key value. Similarly, remove may provoke underflow.<br>
If some super node has an underflow after removing one key value, at this time it has $\left \lceil \frac{m}{2} \right \rceil-2$ key values and $\left \lceil \frac{m}{2} \right \rceil-1$ branches. There are two methods for solving underflow.<br>
<b>Rotation</b>: if this super node v's sibling s has more than $\left \lceil \frac{m}{2} \right \rceil-1$ key value, v can borrow a key value from s with respecting the in-order rule. For example, y move to first one of v, x replace y's orginal position.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_underflow_1.png"/></center>
</p>
<p align="justify">
What if v's lfet sibling and right sibling have no available key value?<br>
<b>Combine</b>: Suppose v's left sibling is s, s has exactly $\left \lceil \frac{m}{2} \right \rceil-1$ key values. We combine s, v and their parent as a new super node with a number of 
$$\left \lceil \frac{m}{2} \right \rceil-1+\left \lceil \frac{m}{2} \right \rceil-2+1<m-1$$

At the same time, combine y's left pointer and right pointer together at the new super node. Naturally, this process will pass upward until root node.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/b_tree_underflow_2.png"/></center>
</p>
<p align="justify">
Remove is in $O(h)$<br><br>
</p>

### 7.3 Red-Black tree
<p align="justify">
Ephemeral data structure: some state exists in one moment. If we have a dynamic change on some data structure such as list, stack or graph, its state will change without perserving its ancient state.<br><br>

Persistent structure: support a visit for ancient state. How to realize this structure? A sample method is to preserve its each history version, but this way will cause much waste for some data because of duplicated copy.<br><br>

Take a BBST as an instance, we preserve all history version (h = |history|). Each search is in $O(logh+logn)$, because we have to locate version then search some element. Totally, time/space complexity is in $O(h+n)$.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_1.png"/></center>
</p>
<p align="justify">
In fact, we update a few elements between two neighbor versions and most elements are not updated. This is a relationship. So we just maintain some updated elements. Then time complexity for sigle version (or augmentation) is in $O(logn)$ and total complexity is in $O(n+h)$.<br><br>

We want reduce time complexity to $O(n+h)$. So we have to require a topological difference in $O(1)$ between 2 neighbor versions. Unluckily, most BBST cannot guarantee this requirement. For example, we have a dynamic operation on an AVL such as insert or remove. In order to keep its balance, we will do some rotations. It's ok for inserting because of at most 2 rotations, but the worst condition for removing is in $O(logn)$. Therefore, we need a specific tree to satisfy our requirement (topological structure variation in $O(1)$). This is Red-Black tree.
</p>

#### 7.3.1 Definition
<p align="justify">
From the name of Red-Black tree, it has two kind of colors: red and black. We supply external nodes for each leaf node of Red-Bed tree so that it's a true BST(each node has two children even if its children are null).<br><br>

A Red-Black tree can be defined as follows:<br>
1) root must be black<br>
2) all external nodes must be black<br>
3) for other nodes, if they are red, their children must be black (red's children and parent are black)<br>
4) from root to any external node, the number of black nodes passed must be identic.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_2.png"/></center>
</p>

#### 7.3.2 Lifting
<p align="justify">
In order to better understand Red-Black tree. We need a technique -- lifting. Concretely, we lift each red node one level so that it has a same height as its parent.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_lift_1.png"/></center>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_lift_2.png"/></center>
</p>
<p align="justify">
We can observe that all nodes in the last level has a same height after lifting. In fact, this is a (2, 4) B-tree now. Besides, a Red-Black tree is balanced because B-tree is balanced. If there is n internal nodes in a Red-Black tree, its height is $h = O(logn)$<br><br>

Black height (bh): a number of balck node in a path from root to any external node. According to Red-Black tree's property, a red node's child and parent must be black, which means a Red-Black tree's height is between one black height and 2 black height. How to compute its black height? Answer is its equivalent B-tree's height.
$$bh \leqslant 1+log_{\left \lceil \frac{m}{2} \right \rceil} \frac{n+1}{2} \leqslant log_{2} (n+1)$$

A Red-Black tree's height
$$bh \leq h \leq 2\times bh$$
$$log_{2}(n+1) \leq h \leq 2\times log_{2}(n+1)$$
</p>

#### 7.3.3 Insert
<p align="justify">
Algorithm:<br>
Suppose a node named x to be inserted, according to BBST's insert algorithm, we insert x as a leaf node with two external children and color x in red. At this time, definition 1), 2), 4) are satistied but 3) is not for sure. Because there is a risk x's parent p is red. We call this case double red. If p is black, everything is ok, otherwise, we have to get rid of double red.<br><br>

In addition, we are sure g is black if p is red but we are not sure g's anothr child u is red or black.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_1.png"/></center>
</p>
<p align="justify">
According to u's color, we have 2 situations.<br><br>

<b>If u is black</b>, p and x is red, we consider three generations g, p, x. Naturally, there are 4 kinds of topological structure: zagzag, zigzig, zagzig and zigzag. Here, we only take zigzig and zagzig into account because of symmetry. In this case, u may be an external node or a leave node, but this tree's black doesn't change. We lift all red node one level to form a B-tree (4-way is legal) then we can observe a super node with x, p, g or p, x, g. No matter whcih condition, two red node are adjacent. What we should do is reorginize this tree value so that red-black-red. For zigzig, exchange p and g's color; for zagzig, exchange x and g's color.<br><br>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_2.png"/></center>
</p>
<p align="justify">
Another way is 3+4 reconstruction, we sort a, b, c as well as their subtree (if not null) to reconstruct a BBST and color a, c in red and the others in black. This method can handle all topological structures.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_3.png"/></center>
</p>
<p align="justify">
Only one recolor is enough to get rid of double color and the Red-Black tree's topological structure doesn't change, so complexity for this situation is in $O(1)$.<br><br>

<b>If u is red</b>, similarly we take three generations g, p, x into account for zigzig and zagzig. We lift red nodes, then we can observe the super node has 4 key values with an overflow happened. So, we need to split the super node to eliminate overflow. Equivalently, in the view of Red-Black tree, p and u change to black, g changes to red. Take care that g goes up one level (or g gets red) may cause a new double red, so we can continue our algorithm until no double red. Although, double red will pass upward and total recolor may be in $O(logn)$, our topological structure of Red-Black tree doesn't change. During this process, what we only do is change color instead of rotations. So, topological structure variation is in $O(1)$.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_4.png"/></center>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_5.png"/></center>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_insert_6.png"/></center>
</p>
<p align="justify">
In other word, reconstruction is in $O(1)$. Why do we focus on reconstruction more than coloring? Because reconstruction of tree has a relationship with persistent structure. If some sturcture os persistent, the less reconstruction happens, the better.
</p>

#### 7.3.4 Remove
<p align="justify">
Algorithm:<br>
Suppose we want to remove x, first of all we have to find x's successor r. According to normal BST's algorithm, we usually find the leftmost child in x's right subtree. Attention, we ignore external nodes. If one of x and r is red, everything is ok, otherwise, we have a double black (double red is impossible).
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_1.png"/></center>
</p>
<p align="justify">
If both x and r are black, after removing x, we reduce our black height by 1, so rule 4 is not satisfied. Besides, we call x's parent p and p's another child s (x's sibling). We have four cases.<br><br>

<b>Case 1: if s is black and has at least one red child t</b>
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_2.png"/></center>
</p>
<p align="justify">
We take use of B-tree to elaborate why it works. In fact, after remvoing x, an underflow happens in the supernode of x. Lucily, x can borrow a key value form its sibling s by rotating.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_3.png"/></center>
</p>
<p align="justify">
<b>Case 2: if s is black with two black children and p is red</b><br>
x/r keeps balck, s changes to be red and p changes to be black.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_4.png"/></center>
</p>
<p align="justify">
Is an underflow possible to propagate upward? No, because p is red so p's parent must be black. In the viwe of B-tree, there must be a value with p together in some super node. Although p goes down to combine with its children, the original super node couldn't have an underdlow.<br><br>

<b>Case 3: if s is black with two black children and p is black</b><br>
s changes to be red.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_5.png"/></center>
</p>
<p align="justify">
In the view of B-tree, un underflow continues to propagate upwards so such a combination may be in $O(logn)$. However, in the view of Red-Black tree, there is no strcuctural variation. What we need do is color s in red.<br><br>

<b>Case 4: if s is red (obviously with 2 black children or null)</b><br>
zig(p) (or zag(p)), s changes to be black and p changes to be red.
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_6.png"/></center>
</p>
<p align="justify">
After such an operation, we do not solve double black and rule 4 is still unsatisfied. But we transform case 4 to case 1 or case 2. Then we do the same thing like case 1 or case 2 to get rid of double black.<br><br>

In a word, remove a node in $O(logn)$, with at most $O(logn)$ coloring, one 3+4 reconstruction (rotation), one single rotation (zig or zag).
<center><img src="https://raw.githubusercontent.com/chaopan95/chaopan95.github.io/master/_imgs/DSA/rb_tree_remove_7.png"/></center>
</p>


### 树
#### 二叉树
##### 前序遍历
##### 中序遍历
##### 后序遍历
##### 层序遍历
##### 线索树
#### 并查集
#### 线段树
#### 字典树
##### Leetcode 208. 实现 Trie (前缀树)
{% highlight C++ %}
struct TrieNode {
    vector<char> val;
    vector<TrieNode*> next;
    bool isEnd;
    TrieNode() {
        val.resize(26, ' ');
        next.resize(26, nullptr);
        isEnd = false;
    }
    TrieNode(char x) {
        val.resize(26, ' ');
        val[x - 'a'] = x;
        next.resize(26, nullptr);
        isEnd = false;
    }
};

class Trie {
    TrieNode *root;
public:
    /** Initialize your data structure here. */
    Trie() {
        root = new TrieNode();
    }
    
    /** Inserts a word into the trie. */
    void insert(string word) {
        TrieNode *curNode = root;
        for (const char &ch : word) {
            int idx = ch - 'a';
            if (curNode->next[idx] == nullptr) {
                curNode->val[idx] = ch;
                curNode->next[idx] = new TrieNode();
            }
            curNode = curNode->next[idx];
        }
        curNode->isEnd = true;
    }
    
    /** Returns if the word is in the trie. */
    bool search(string word) {
        TrieNode *curNode = root;
        for (const char &ch : word) {
            int idx = ch - 'a';
            if (curNode->val[idx] != ch) { return false; }
            curNode = curNode->next[idx];
        }
        return curNode->isEnd;
    }
    
    /** Returns if there is any word in the trie that starts with the given prefix. */
    bool startsWith(string prefix) {
        TrieNode *curNode = root;
        for (const char &ch : prefix) {
            int idx = ch - 'a';
            if (curNode->val[idx] != ch) { return false; }
            curNode = curNode->next[idx];
        }
        return true;
    }
};

/**
 * Your Trie object will be instantiated and called as such:
 * Trie* obj = new Trie();
 * obj->insert(word);
 * bool param_2 = obj->search(word);
 * bool param_3 = obj->startsWith(prefix);
 */
{% endhighlight %}